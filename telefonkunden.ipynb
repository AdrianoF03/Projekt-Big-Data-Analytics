{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV-Datei einlesen\n",
    "telefonkunden = pd.read_csv('telefonkunden.csv')\n",
    "\n",
    "# Wie sieht der Datensatz aus?\n",
    "print(telefonkunden.head)\n",
    "telefonkunden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offenbar wurden Daten von 1000 Kunden gesammelt.\n",
    "# Beschreibung des Datensatzes:\n",
    "# Der Datensatz enthält Informationen über Telefonkunden, die in vier verschiedene Kundentypen (custcat) eingeteilt sind.\n",
    "# Diese Kategorien können unterschiedliche Nutzungsmuster, Vertragslaufzeiten oder Kundenwerte repräsentieren.\n",
    "# Die Daten umfassen 8 Merkmale, die mit der Kundenkategorie in Verbindung stehen: \n",
    "# - tenure (Monate der Kundenbindung)\n",
    "# - age (Alter des Kunden)\n",
    "# - income (Einkommen in Tausend Dollar)\n",
    "# - ed (Bildungsniveau)\n",
    "# - employ (Anzahl der Jahre in Beschäftigung)\n",
    "# - address (Dauer der aktuellen Wohnadresse in Jahren)\n",
    "# - marital (Familienstand: 1 = verheiratet, 0 = unverheiratet)\n",
    "# - reside (Anzahl der Personen im Haushalt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. die Daten kennenlernen\n",
    "\n",
    "# Mit dem Befehl describe() können summary statistics aufgerufen werden:\n",
    "telefonkunden.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot: Histogram of numeric columns\n",
    "telefonkunden.hist(figsize=(10, 6), bins=30, color='skyblue', edgecolor='black', layout=(3, 4))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_cols = telefonkunden.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    telefonkunden[col].plot(kind='hist', bins=30, edgecolor='black')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 2. den Datensatz in Trainings- und Lerndatensatz aufteilen\n",
    "\n",
    "# Dafür erstellen wir zunächst (wie auch bei den Weinen) zwei separate Datensätze mit den Input- (X) und der Outputvariablen (Y).\n",
    "X = telefonkunden.drop(columns=['custcat'])\n",
    "Y = telefonkunden.custcat\n",
    "X.head()\n",
    "Y.head()\n",
    "\n",
    "# Jetzt können wir wieder mit train_test_split aus scikit-learn den Datensatz in Trainings- und Testdaten aufteilen\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_training, X_test, Y_training, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1, stratify = Y)\n",
    "# Wie vorher: Wir teilen in 20% Lern- und 80% Testdaten auf (test_size), lassen die Aufteilung zur Reproduzierbarkeit der Ergebnisse immer gleich aufteilen (random_state), und sorgen im Trainingsdatensatz für den gleichen Anteil an Patienten mit und ohne Diabetes wie im gesamten Datensatz (stratify).\n",
    "\n",
    "# Nun wird das Modelll trainiert. Wir verwenden zunächst k=3, d.h. wenn ein Testpunkt mindestens 2 von 3 nächste Nachbarn hat, die Diabetes (=1) haben, bekommt der Testpunkt das Label Diabetes (=1), wenn mindestens 2 der 3 nächsten Nachbarn kein Diabetes (=0) hat, bekommt der Testpunkt das Label kein Diabetes (=0).\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "vorhersage_scikit = knn.fit(X_training, Y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 3. eine Vorhersage mit dem kNN-Algorithmus treffen\n",
    "vorhersage_scikit=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Am Ergebnisarray sieht man z.B. dass die ersten 4 Patienten im Testdatensatz vom Algorithmus als \"kein Diabetes\" klassifiziert wurde, der 5. Patient mit \"Diabetes\". Nun können wir wieder vergleichen, ob die jeweiligen Patienten im Testdatensatz tatsächlich Diabetes haben oder nicht, und ob das Modell dies richtig vorhergesagt hat. Dazu bedienen wir uns wieder dem Genauigkeits-Score, also dem Anteil richtiger Vorhersagen verglichen mit allen Vorhersagen.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, vorhersage_scikit))\n",
    "\n",
    "# Alternativ gibt es die Funktion score():\n",
    "knn.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die bisherige Vorgehensweise hieß Holdout-Methode: Man reserviert eine Menge als Testdaten, den Rest als Trainingsdaten. Allerdings kann dies zu Probleme führen: Vielleicht wurden die Daten unglücklich aufgeteilt?Zur Lösung bedient man sich der sog. k-fache Kreuzvalidierung, wie auch in der Vorlesung besprochen: Bei der Kreuzvalidierung wird der Datensatz zufällig in Gruppen aufgeteilt. Eine der Gruppen wird als Testsatz und der Rest als Trainingssatz verwendet. Das Modell wird mit dem Trainingssatz trainiert und mit dem Testsatz bewertet. Dann wird der Prozess wiederholt, bis jede einzelne Gruppe als Testsatz verwendet wurde. Bei der 5-fachen Kreuzvalidierung werden also die Daten in 5 Gruppen aufgeteilt und 5-mal angepasst und bewertet, wobei jedes Mal der Genauigkeitswert in einem Array abgespeichert wird. So hat jede der 5 Gruppen eine Chance, als Testdatensatz zu dienen.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Neuen Klassifikator verwenden, mit unserem idealen k=3\n",
    "klassifikator_kreuzvalidierung = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Genauigkeiten mit einem trainierten Modell mit 5 Gruppen\n",
    "kreuzvalidierung_genauigkeiten = cross_val_score(klassifikator_kreuzvalidierung, X, Y, cv = 5)\n",
    "\n",
    "# Genauigkeiten ausgeben\n",
    "print(kreuzvalidierung_genauigkeiten)\n",
    "# Nehmen wir einfach mal den Mittelwert dieser Genauigkeiten, und sehen, dass wir die Genauigkeit nochmals erhöhen konnten von ca. 66% auf ca. 71%!\n",
    "print(np.mean(kreuzvalidierung_genauigkeiten))\n",
    "# Wir konnten also eine Erhöhung der Genauigkeit erreichen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir haben bisher k (also die Anzahl an nächsten Nachbarn, die der Algorithmus berücksichtigen soll) einfach geraten, hatten aber keinerlei Intuition, ob das ein guter Parameter für das Modell und die Daten ist. Was ist aus Sicht der Genauigkeit der Vorhersage ein optimales k? Dazu könnte man obigen Code für verschiedene k ausprobieren (egal ob eigener Code oder vorgefertigte Python-Funktion) und das k wählen, das die höchste Genauigkeit liefert. Ist aber sehr mühsam. Schreiben wir also eine Schleife, die für uns verschiedene k's in den knn-Algorithmus einsetzt, und uns anschließend dasjenige k liefert, bei dem die höchste Genauigkeit erreicht wird (sprich bei dem die meisten Patienten im Testdatensatz richtig klassifiziert werden). Dies nennt man wie im Skript besprochen \"Hyperparameter-Optimierung\".\n",
    "\n",
    "# Dies kann man mit GridSearchCV erreichen. Damit wird das Modell mehrfach mit einer Reihe von Parametern trainiert, die eingegeben werden. Auf diese Weise kann das Modell mit jedem Parameter getestet und die optimalen Werte herausgefunden werden, um die besten Genauigkeitsergebnisse zu erhalten. \n",
    "# Dabei erstellt man zunächst ein Dictionary mit allen Werten von k, die einen interessieren (z.B. von 1 bis 100). Anschließend übergibt man jedes k einem neuen Klassifkiator KNeighborsClassifier. GridSearchCV ermittelt dann für eine gegebene Menge an Gruppen (z.B. 5 Gruppen mit 5 Vorhersagen, also 4 Trainings- und 1 Lerndatensatz, wobei jeder Datensatz über alle 5 Vorhersagen hinweg genau 1-mal Testdatensatz und genau 4-mal Trainingsdatensatz war). Jede dieser 5 Vorhersagen wird mit jedem Wert von k aus dem Dictionary durchgeführt. Bei 30 Werten für k und 5 Vorhersagen für jedes k wären dies also 100*5=500 Durchläufe, mit 500 Genauigkeits-Scores. GridSearchCV ermittelt daraus dann den höchsten Genauigkeits-Score, und schaut, bei welchem k dieser erreicht wurde. Dies ist dann unser optimales k für die Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Definieren wir zunächst einen neuen Klassifikator:\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "# Nun erstellen wir das Dictionary mit den k-Werten für die Hyperparameter-Optimimerung, die uns interessieren:\n",
    "k_grid = {'n_neighbors': np.arange(1, 50)}\n",
    "\n",
    "# Nun lassen wir die Grid-Suche für jedes k durchlaufen, jeweils mit einer 5-fachen Kreuzvalidierung:\n",
    "knn_grid = GridSearchCV(knn2, k_grid, cv = 5)\n",
    "\n",
    "# Nun trainieren wir das Modell mit den Daten und den darüber definierten Parametern:\n",
    "knn_grid.fit(X, Y)\n",
    "\n",
    "# Was ist nun die beste Anzahl an Nachbarn?\n",
    "print(knn_grid.best_params_)\n",
    "\n",
    "# Der Genauigkeits-Score bei dieser Anzahl an Nachbarn ist nochmal höher, wir sind von 37,5% auf 37,4% gekommen!\n",
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Man kann die Funktion auch alle Genauigkeits-Scores ausgeben lassen. Dies sind also für jedes k die durchschnittlichen Werte der Genauigkeits-Scores aus je allen 5 Durchläufen der Kreuzvalidierung! Hier sieht man nochmals an der Stelle 14 den höchsten Score, und ebenfalls den bisherigen Score von 71%, den wir bei k=3 hatten!\n",
    "scores=knn_grid.cv_results_['mean_test_score']\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dies kann man auch noch grafisch darstellen. Dafür brauchen wir die matplotlib als gute Bibliothekt für Datenvisualisierung:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wir definieren eine Bildgröße\n",
    "plt.figure(figsize=(10,6))\n",
    "# Wir plotten auf der x-Achse von 1 bis 60 (also die k's die wir oben in der for-Schleife durchprobiert haben)\n",
    "plt.plot(range(1,50),scores)\n",
    "# Wir beschriften noch die Achsen\n",
    "plt.title('Genauigkeit vs. k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Genauigkeit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Schaubild bestätigt unsere Vermutung aus dem Skript zu overfitting und underfitting:\n",
    "# - Die Vorhersagegenauigkeit auf den Testdaten ist bei niederigen k schlecht, da in diesem Fall das Modell mit nur wenigen nächsten Nachbarn trainiert wurde, sodass die Genauigkeit in den Trainingsdaten zwar maximiert wurde, aber diese Vorhersagen eben nur auf den Trainingsdatensatz passen. Warum? Weil durch die kleinen k's auch zufälliges \"Rauschen\" (z.B. Ausreißer) als systematisch betrachtet wurden. Das Modell sagt daher für die Testdaten weniger genau voraus. Dies nennt man \"overfitting\"!\n",
    "# - Die Vorhersagegenauigkeit auf den Testdaten ist bei hohen k schlecht, da in diesem Fall das Modell mit vielen nächsten Nachbarn trainiert wurde, sodass das Modell zu allgemein ist, und manche systematischen Bestandteile in den Daten nicht erkennt. Dies nennt man \"underfitting\"!\n",
    "# - Nur bei einem mittleren k (hier 9 oder 10) schafft man einen Kompromiss aus overfitting und underfitting!\n",
    "\n",
    "#Text von Höchenberger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Features und Zielvariable definieren\n",
    "df = pd.read_csv('telefonkunden.csv')\n",
    "# Die Zielvariable 'custcat' wird für die Kundensegmentierung verwendet\n",
    "X = df.drop(columns=['custcat'])\n",
    "y = df['custcat']\n",
    "\n",
    "# Daten normalisieren\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Grid Search zur Optimierung des RandomForest-Modells\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Verwirrungsmatrix erstellen und visualisieren\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Vorhergesagte Klasse')\n",
    "plt.ylabel('Tatsächliche Klasse')\n",
    "plt.title('Verwirrungsmatrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Features und Zielvariable definieren\n",
    "# Die Zielvariable 'custcat' wird für die Kundensegmentierung verwendet\n",
    "X = df.drop(columns=['custcat'])\n",
    "y = df['custcat']\n",
    "\n",
    "# Daten normalisieren\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Grid Search zur Optimierung des Entscheidungsbaum-Modells\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Verwirrungsmatrix erstellen und visualisieren\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Vorhergesagte Klasse')\n",
    "plt.ylabel('Tatsächliche Klasse')\n",
    "plt.title('Verwirrungsmatrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Korrelationsmatrix\n",
    "corr = telefonkunden.corr()\n",
    "\n",
    "# Größe der Figur anpassen\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Heatmap erstellen\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', center=0, linewidths=0.5, linecolor='black')\n",
    "\n",
    "# Titel und Achsenbeschriftungen hinzufügen\n",
    "plt.title('Korrelationsmatrix der Telefonkunden', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "telefonkunden = pd.read_csv('telefonkunden.csv')\n",
    "\n",
    "# Pair Plot\n",
    "sns.pairplot(telefonkunden, hue='custcat', palette='coolwarm')\n",
    "plt.title('Pair Plot der Telefonkunden')\n",
    "plt.show()\n",
    "\n",
    "# Distribution Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(telefonkunden['feature_name'], kde=True, bins=30, color='blue')\n",
    "plt.title('Verteilung von Feature_Name')\n",
    "plt.xlabel('Feature_Name')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='custcat', y='feature_name', data=telefonkunden, palette='coolwarm')\n",
    "plt.title('Box Plot von Feature_Name nach Kundensegment')\n",
    "plt.xlabel('Kundensegment')\n",
    "plt.ylabel('Feature_Name')\n",
    "plt.show()\n",
    "\n",
    "# Count Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='custcat', data=telefonkunden, palette='coolwarm')\n",
    "plt.title('Anzahl der Kunden in jedem Segment')\n",
    "plt.xlabel('Kundensegment')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='feature1', y='feature2', hue='custcat', data=telefonkunden, palette='coolwarm')\n",
    "plt.title('Scatter Plot von Feature1 vs Feature2')\n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap of Missing Values\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(telefonkunden.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Heatmap der fehlenden Werte')\n",
    "plt.show()\n",
    "\n",
    "# Violin Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='custcat', y='feature_name', data=telefonkunden, palette='coolwarm')\n",
    "plt.title('Violin Plot von Feature_Name nach Kundensegment')\n",
    "plt.xlabel('Kundensegment')\n",
    "plt.ylabel('Feature_Name')\n",
    "plt.show()\n",
    "\n",
    "# !!!info:feature namen mit namen im datensatz austauschen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the selected features with actual column names\n",
    "selected_features = ['region', 'tenure', 'age', 'income', 'ed', 'employ', 'reside'] \n",
    "\n",
    "# Datenaufteilung in Features (X) und Zielvariable (y)\n",
    "X = telefonkunden[selected_features]\n",
    "Y = telefonkunden['custcat']\n",
    "\n",
    "# Datenaufteilung in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n",
    "\n",
    "# Hyperparameter-Tuning für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telefonkunden.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "telefonkunden = pd.read_csv('telefonkunden.csv')\n",
    "\n",
    "# Define the selected features with actual column names\n",
    "selected_features = ['region', 'tenure', 'age', 'income', 'ed', 'employ', 'reside']\n",
    "\n",
    "# Datenaufteilung in Features (X) und Zielvariable (y)\n",
    "X = telefonkunden[selected_features]\n",
    "Y = telefonkunden['custcat']\n",
    "\n",
    "# Datenaufteilung in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n",
    "\n",
    "# Hyperparameter-Tuning für den Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', random_state=1, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Hyperparameter-Tuning für den SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=1), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Hyperparameter-Tuning für den Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(random_state=1), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_gb = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_gb.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Hyperparameter-Tuning für den KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Hyperparameter-Tuning für die logistische Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=1), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell auswählen\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Genauigkeit:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
